{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iYMuTf62esO2",
    "outputId": "382c3c55-9913-480d-f119-06eece858775",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bQZk_aZvfq7s"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "from transformers import (\n",
    "    DataCollatorForSeq2Seq,\n",
    "    MT5ForConditionalGeneration,\n",
    "    MT5Tokenizer,\n",
    "    pipeline,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    ") \n",
    "import evaluate\n",
    "import numpy as np\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "709dbbd87d9748bcbd260b88469d342d",
      "dc78087844ad4ecfa6856fe006a69635",
      "2feb4091ffb24ac88c6f4908cbcbe6c0",
      "1694044776c140648300869f43fc48bb",
      "b97a81546451420883109c625b55f25a",
      "9d6a52a8136649acbde0c7497242b044",
      "b66ba5bd8eb44c0a9d07afa33fe4bf0e",
      "07227f735cbf498ab21aab920661b66f",
      "133be2832be4467d92214a8b7534b1e6",
      "4e5fe7e1aabb4a0d890f07b67d080201",
      "9766f263b45740e39717d0369caa8c44"
     ]
    },
    "id": "nynyn77Dfh7b",
    "outputId": "fc9cc1fc-079a-43ef-b4a5-f8d017d4420b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "tokenizer = MT5Tokenizer.from_pretrained(\"google/mt5-small\")  # cointegrated/rut5-small google/mt5-small\n",
    "model = MT5ForConditionalGeneration.from_pretrained('google/mt5-small')\n",
    "\n",
    "# tokenizer = MT5Tokenizer.from_pretrained(\"results/checkpoint-121500\")  # это если мы хотим подгрузить веса модели которую уже обучали\n",
    "# model = MT5ForConditionalGeneration.from_pretrained('results/checkpoint-121500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_kYLU1PYfxqE"
   },
   "outputs": [],
   "source": [
    "max_target_tokens_count = 128\n",
    "max_source_tokens_count = 1024\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = examples[\"text\"]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_source_tokens_count, truncation=True)\n",
    "\n",
    "    labels = tokenizer(text_target=examples[\"summary\"], max_length=max_target_tokens_count, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    \n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "63b4cb1046094f76b16a8d850836ee8c",
      "462fe0525afe4e98b91fbbac96667de7",
      "bc47889ca9c84981a9c4cf0f51684e9c",
      "49dabea105f641029e264ff04e038566",
      "534f48ba70894f3e8a08a1475f722542",
      "f8d81eb5c72f48559f34b94a0311924b",
      "d7cb38d1bba8410db73ff8939feb0c0c",
      "5c18e6505317441ab5a30de4bc2ec51e",
      "ee9f44cd7cb54cf58ea29651e340037f",
      "a475e18e42d7404bae8591f80c602b33",
      "5d562be777d345f2a1253ff4ec4f4323"
     ]
    },
    "id": "ZHAZ-uoTsfti",
    "outputId": "e28f0da4-8aee-4068-8b6b-11512fa063b5"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset('IlyaGusev/gazeta',revision=\"v2.0\")\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lMebQnimgPO8"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200,
     "referenced_widgets": [
      "ff23f2a7cefa4809beecf6da80fd8efc",
      "69a4a63657034c4295f524adf4bd055b",
      "e06a33459779440b84724bdb7d56adbc",
      "315d64930da34ae5a1fd8c973d2a1278",
      "23e80f6e4d3e4f7a8b609725b5e64c0a",
      "452a42a5468d47918e3550e44ce76d74",
      "8655d3b692e24de4a4cd461b40310b45",
      "855bba6d5f2740a1a0206d1fd9039921",
      "e4ee034a586040388581fa0aef1f2c82",
      "a130d6063bd84632b1aa8bf2ee4d1072",
      "fe55274fedd344f0aa96e805741d5a42",
      "7352a236cfe04323a0b091203b6339fe",
      "829623d832d24200b9433dc3a6a488cd",
      "4aa20aede47a4596a6ca4bd9076026be",
      "6bb04ab5465b43c8b0d77d30729e6b98",
      "6f334cf7f8584a16880bdff8379b7c63",
      "120e00cd79cc4e5f8a84bd44eebcb09c",
      "d3ba979e5f294a25bdf53041460234aa",
      "2a1b2bbff2824ee9b787ffb852de969e",
      "5ccf5e216b6f42cfafbba9c45173f91b",
      "bd892f8698a7452bae579ddf28270706",
      "eb15a093cd584a2d9dd9f17ea36e14f6",
      "a7dcc0cf145d452fadf75d9f1f3164f2",
      "dbda036e9c8147d3bb10eaeb99d93d50",
      "ac01fb72065d417aa3435224f9dcca36",
      "0b49b00d2bb84554a6b3f9f4f0c75a27",
      "fdd0e891b78e46baa47a6c37f84f14bf",
      "1be56407bf5e4e3789d92d6695f630d6",
      "bfafb15869f64905be845cabf1f4af66",
      "45905a6165e6408d822c5a4ab44776d8",
      "639281d17db14e2cb9d1046e26858dab",
      "6692adc9f1e64a03808d2f2042a7776b",
      "cf74bc353caa41ae9bc973b4c67b1a27",
      "99a9425c0d0b4c4497fb7c8599c84951",
      "affe68c841a343f8bf73b46ef414d9e8",
      "26e686a834fe467d974b83e310835ced",
      "f25d6d594d024fb3862d4d4466f6d9b7",
      "e9e91a9316c14d62b0fc640ed0a706b9",
      "393356139bfb4fd1b0f65d43a8187e3f",
      "1e3f78cc1f2148ae996d9800365265ce",
      "c76c9dbfef1b4c628ebca65c37c4685c",
      "540da5e51f0b48a6836a22bee7d0d150",
      "698c162504884f65babb866a27f5a658",
      "2545fca9cebc4820ba2f30c43ffe5d92"
     ]
    },
    "id": "qRvHK5KugXuk",
    "outputId": "e4028eea-e437-4c87-b647-c1d5ebf57cf6"
   },
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "bleu = evaluate.load(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "wurnyNuHgwyi"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    predictions = np.where(predictions != -100, predictions, tokenizer.pad_token_id)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    \n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    result = {}\n",
    "    result_rouge = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    \n",
    "    # Extract a few results\n",
    "    result.update({key: value * 100 for key, value in result_rouge.items()})\n",
    "    \n",
    "    result_bleu = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    # Extract a few results\n",
    "    result[\"bleu\"] = result_bleu[\"bleu\"] * 100\n",
    "    \n",
    "    # Add mean generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result[\"char_len\"] = np.mean([len(t) for t in decoded_preds])\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gljKqGgQg0tG"
   },
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"/lab4/results\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=25,\n",
    "    logging_steps=25,\n",
    "    learning_rate=4e-4,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=64,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=1,\n",
    "    fp16=False,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=max_target_tokens_count,\n",
    "    generation_num_beams=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "U3g-FfzChIHq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "id": "9S6UxGdRhKrV",
    "outputId": "5f294e2a-908c-4d21-953e-a18ad33730fe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='238' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238/238 11:08:30, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Char Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>3.649400</td>\n",
       "      <td>2.606828</td>\n",
       "      <td>8.884700</td>\n",
       "      <td>2.798500</td>\n",
       "      <td>8.669200</td>\n",
       "      <td>8.728700</td>\n",
       "      <td>3.132000</td>\n",
       "      <td>41.801100</td>\n",
       "      <td>153.214000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.310900</td>\n",
       "      <td>2.503560</td>\n",
       "      <td>12.919900</td>\n",
       "      <td>4.202200</td>\n",
       "      <td>12.663000</td>\n",
       "      <td>12.707900</td>\n",
       "      <td>4.750600</td>\n",
       "      <td>64.995700</td>\n",
       "      <td>229.396400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>3.159900</td>\n",
       "      <td>2.460199</td>\n",
       "      <td>15.243700</td>\n",
       "      <td>5.033900</td>\n",
       "      <td>14.998500</td>\n",
       "      <td>15.044000</td>\n",
       "      <td>5.492100</td>\n",
       "      <td>79.207400</td>\n",
       "      <td>274.548700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.065200</td>\n",
       "      <td>2.445562</td>\n",
       "      <td>15.851500</td>\n",
       "      <td>5.261300</td>\n",
       "      <td>15.566700</td>\n",
       "      <td>15.632500</td>\n",
       "      <td>6.002900</td>\n",
       "      <td>84.889200</td>\n",
       "      <td>295.209000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>3.019600</td>\n",
       "      <td>2.399887</td>\n",
       "      <td>15.633000</td>\n",
       "      <td>5.144200</td>\n",
       "      <td>15.346500</td>\n",
       "      <td>15.438800</td>\n",
       "      <td>5.990600</td>\n",
       "      <td>84.439000</td>\n",
       "      <td>293.492300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.968100</td>\n",
       "      <td>2.392379</td>\n",
       "      <td>15.885500</td>\n",
       "      <td>5.094100</td>\n",
       "      <td>15.549700</td>\n",
       "      <td>15.697400</td>\n",
       "      <td>6.276400</td>\n",
       "      <td>87.922300</td>\n",
       "      <td>306.378200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>2.940200</td>\n",
       "      <td>2.371411</td>\n",
       "      <td>15.701200</td>\n",
       "      <td>5.009200</td>\n",
       "      <td>15.414200</td>\n",
       "      <td>15.532800</td>\n",
       "      <td>6.333000</td>\n",
       "      <td>88.429700</td>\n",
       "      <td>307.653500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.928100</td>\n",
       "      <td>2.370409</td>\n",
       "      <td>16.038300</td>\n",
       "      <td>5.249700</td>\n",
       "      <td>15.725000</td>\n",
       "      <td>15.840900</td>\n",
       "      <td>6.336600</td>\n",
       "      <td>88.164400</td>\n",
       "      <td>306.793600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>2.913200</td>\n",
       "      <td>2.371033</td>\n",
       "      <td>16.293500</td>\n",
       "      <td>5.199700</td>\n",
       "      <td>15.990900</td>\n",
       "      <td>16.089600</td>\n",
       "      <td>6.375000</td>\n",
       "      <td>87.160800</td>\n",
       "      <td>302.993700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=238, training_loss=3.0958816303926358, metrics={'train_runtime': 40122.4096, 'train_samples_per_second': 1.519, 'train_steps_per_second': 0.006, 'total_flos': 6.442993023307776e+16, 'train_loss': 3.0958816303926358, 'epoch': 1.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VZZc5DMmhOEG"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1699' max='1699' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1699/1699 1:26:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.365630626678467,\n",
       " 'eval_rouge1': 16.1474,\n",
       " 'eval_rouge2': 5.2142,\n",
       " 'eval_rougeL': 15.8831,\n",
       " 'eval_rougeLsum': 15.9676,\n",
       " 'eval_bleu': 6.3574,\n",
       " 'eval_gen_len': 86.9866,\n",
       " 'eval_char_len': 302.4871,\n",
       " 'eval_runtime': 5223.6655,\n",
       " 'eval_samples_per_second': 1.3,\n",
       " 'eval_steps_per_second': 0.325,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Barboskiny",
   "language": "python",
   "name": "barboskiny"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
